{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Talk Data - Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives an introduction to working with the various data sets in [Wikipedia\n",
    "Talk](https://figshare.com/projects/Wikipedia_Talk/16731) project on Figshare. The release includes:\n",
    "\n",
    "1. a large historical corpus of discussion comments on Wikipedia talk pages\n",
    "2. a sample of over 100k comments with human labels for whether the comment contains a personal attack\n",
    "3. a sample of over 100k comments with human labels for whether the comment has aggressive tone\n",
    "\n",
    "Please refer to our [wiki](https://meta.wikimedia.org/wiki/Research:Detox/Data_Release) for documentation of the schema of each data set and our [research paper](https://arxiv.org/abs/1610.08914) for documentation on the data collection and modeling methodology. \n",
    "\n",
    "In this notebook we show how to build a simple classifier for detecting personal attacks and apply the classifier to a random sample of the comment corpus to see whether discussions on user pages have more personal attacks than discussion on article pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a classifier for personal attacks\n",
    "In this section we will train a simple bag-of-words classifier for personal attacks using the [Wikipedia Talk Labels: Personal Attacks]() data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Python 3\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import os\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download annotated comments and annotations\n",
    "\n",
    "ANNOTATED_COMMENTS_URL = 'https://ndownloader.figshare.com/files/7554634' \n",
    "ANNOTATIONS_URL = 'https://ndownloader.figshare.com/files/7554637' \n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "path_comment = os.path.isfile(os.path.join(os.getcwd(),'attack_annotated_comments.tsv'))\n",
    "path_annotate = os.path.isfile(os.path.join(os.getcwd(),'attack_annotations.tsv'))\n",
    "\n",
    "# To download only once, and not download it later                \n",
    "if not os.path.isfile(path_comment):\n",
    "    download_file(ANNOTATED_COMMENTS_URL, 'attack_annotated_comments.tsv')\n",
    "if not os.path.isfile(path_annotate):\n",
    "    download_file(ANNOTATIONS_URL, 'attack_annotations.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate the dataframes\n",
    "comments = pd.read_csv('attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115864"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations['rev_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102817</th>\n",
       "      <td>NEWLINE_TOKEN-NEWLINE_TOKENNEWLINE_TOKENImport...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103624</th>\n",
       "      <td>I removed the following:NEWLINE_TOKENNEWLINE_T...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111032</th>\n",
       "      <td>`:If you ever claimed in a Judaic studies prog...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120283</th>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENMy apol...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128532</th>\n",
       "      <td>`Someone wrote:NEWLINE_TOKENMore recognizable,...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  year  logged_in  \\\n",
       "rev_id                                                                       \n",
       "37675   `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002      False   \n",
       "44816   `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002      False   \n",
       "49851   NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002      False   \n",
       "89320    Next, maybe you could work on being less cond...  2002       True   \n",
       "93890                This page will need disambiguation.   2002       True   \n",
       "102817  NEWLINE_TOKEN-NEWLINE_TOKENNEWLINE_TOKENImport...  2002       True   \n",
       "103624  I removed the following:NEWLINE_TOKENNEWLINE_T...  2002       True   \n",
       "111032  `:If you ever claimed in a Judaic studies prog...  2002       True   \n",
       "120283  NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENMy apol...  2002       True   \n",
       "128532  `Someone wrote:NEWLINE_TOKENMore recognizable,...  2002       True   \n",
       "\n",
       "             ns  sample  split  \n",
       "rev_id                          \n",
       "37675   article  random  train  \n",
       "44816   article  random  train  \n",
       "49851   article  random  train  \n",
       "89320   article  random    dev  \n",
       "93890   article  random  train  \n",
       "102817     user  random  train  \n",
       "103624  article  random  train  \n",
       "111032  article  random    dev  \n",
       "120283  article  random    dev  \n",
       "128532  article  random  train  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To visualize the data format\n",
    "comments.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations['attack'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>quoting_attack</th>\n",
       "      <th>recipient_attack</th>\n",
       "      <th>third_party_attack</th>\n",
       "      <th>other_attack</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>1362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37675</td>\n",
       "      <td>2408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37675</td>\n",
       "      <td>1493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37675</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37675</td>\n",
       "      <td>170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37675</td>\n",
       "      <td>176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37675</td>\n",
       "      <td>481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37675</td>\n",
       "      <td>487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37675</td>\n",
       "      <td>578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37675</td>\n",
       "      <td>1127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  quoting_attack  recipient_attack  third_party_attack  \\\n",
       "0   37675       1362             0.0               0.0                 0.0   \n",
       "1   37675       2408             0.0               0.0                 0.0   \n",
       "2   37675       1493             0.0               0.0                 0.0   \n",
       "3   37675       1439             0.0               0.0                 0.0   \n",
       "4   37675        170             0.0               0.0                 0.0   \n",
       "5   37675        176             0.0               0.0                 0.0   \n",
       "6   37675        481             0.0               0.0                 0.0   \n",
       "7   37675        487             0.0               0.0                 0.0   \n",
       "8   37675        578             0.0               0.0                 0.0   \n",
       "9   37675       1127             0.0               0.0                 0.0   \n",
       "\n",
       "   other_attack  attack  \n",
       "0           0.0     0.0  \n",
       "1           0.0     0.0  \n",
       "2           0.0     0.0  \n",
       "3           0.0     0.0  \n",
       "4           0.0     0.0  \n",
       "5           0.0     0.0  \n",
       "6           0.0     0.0  \n",
       "7           0.0     0.0  \n",
       "8           0.0     0.0  \n",
       "9           0.0     0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To visualize the data format\n",
    "annotations.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels a comment as an atack if the majority of annotators did so\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = annotations.groupby('rev_id')['attack'].median() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "#Remove punctuations\n",
    "string.punctuation\n",
    "def remove_punct(text):\n",
    "    text  = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "# Apply the method on comment and remove punctuations\n",
    "comments['comment'] = comments['comment'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>This is not creative  Those are the dictionary definitions of the terms insurance and ensurance as properly applied to destruction  If you dont understand that fine legitimate criticism Ill write up three man cell and bounty hunter and then it will be easy to understand why ensured and insured are different  and why both differ from assured  The sentence you quote is absolutely neutral  You just arent familiar with the underlying theory of strikeback eg submarines as employed in nuclear warfare guiding the insurance nor likely the three man cell structure that kept the IRA from being broken by the British  If thats my fault fine I can fix that to explain  But theres nothing personal or creative about it  Im tired of arguing with you  Re the other article multiparty turns up plenty and there is more use of mutually than mutual  If I were to apply your standard Id be moving Mutual Assured Destruction to talk for not appealing to a Reagan voters biases about its effectiveness and for dropping the ly  There is a double standard in your edits  If it comes from some US history book like peace movement or MAD as defined in  you like it even if the definition is totally useless in  and only of historical interest    If it makes any evenobvious connection or implication from the language chosen in multiple professionspecific terms you consider it somehow nonneutral  Gandhi thinks eye for an eye describes riots death penalty and war all at once but you dont  What do you know that Gandhi doesnt  Guess what  reality is not neutral  Current use of terms is slightly more controversial  Neutrality requires negotiation and some willingness to learn  This is your problem not mine  You may dislike the writing fine that can be fixed  But disregarding fundamental axioms of philosphy with names that recur in multiple phrases or failing to make critical distinctions like insurance versus assurance versus ensurance which are made in one quote by an Air Force general in an incontext quote is just a disservice to the reader  If someone comes here to research a topic like MAD they want some context beyond history  If this is a history book fine its a history book  But that wasnt what it was claimed to be</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>the term standard model is itself less NPOV than I think wed prefer   if its newage speak then a lot of oldage people speak it  Karl Popper the Pope etc  heres Karl Poppers view of this   The clearest title for this article would be particle physics cosmology  but as I say that would require broader treatment of issues like the Anthropic Principle cognitive bias beyond the particle physics zoo etc   as to accelerators its clear that while they are in use someone is still looking for particles  So this is not yet a settled cosmology so certain that we abandon the search nor is it an arbitrary foundation ontology as you suggest not subject to question</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>True or false the situation as of March  was such  A Saudi proposal of Land for Peace AND recognition by ALL arab countries was made The day the proposal was to be made formal by the Arab League was the day the Israelis under the command of Ariel Sharon began the invasion of the Palestinian selfrule areas userArab</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next maybe you could work on being less condescending with your suggestions about reading the naming conventions and FDL both of which I read quite a while ago thanks I really liked the bit where you were explaining why you had no interest in fixing things I complained about because you felt insulted yet you were being extremely insulting at the time With any luck you can learn to be less of a jerk GregLindahl</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102817</th>\n",
       "      <td>Important note for all sysops There is a bug in the administrative move feature that truncates the moved history and changes the edit times  Please do not use this feature until this bug is fixed More information can be found in the talk of  and  Thank you</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103624</th>\n",
       "      <td>I removed the following  All names of early Polish rulers are ficticious and therefore this index naming Oda von Haldensleben and her husband Dagome records for the first time rulers of the Polanen tribe Therefore it is indicated as being the first document of the later developing land named Poland  This is quite a comment All names are fictitious It deserves at least some backing</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111032</th>\n",
       "      <td>If you ever claimed in a Judaic studies program that ultraOrthodox Jews dont have rabbis or dont have synagogues you would be laughed out of the room   I am beginning to see the problem you have You see you do not know how to read what other people say without attaching your personal bias to it Never once did I say that ultraOrthodox Jews have no rabbis or synagogues I DID say that the role of the rabbi and synagogue in ultraOrthodox Judaism is minimal when compared with say Conservative Judaism They are not clergy in the traditional Western sense of the word That is a fact As for synagogues they exist but they are not essential Minyan a quorum of ten adult males in ultraOrthodox law is essential You can have a minyan without a synagogue but a synagogue without a minyan is an empty building You can laugh all you want but it doesnt change the facts It may seem strange to you but take the statement to anyone who actually knows something I want to know who laughs then   If you ever claimed in a recognized Judaica studies program that a significant number of ultraOrthodox rabbis accept and follow Modern Orthodox responsa instead of their own people would look at you as if you had two heads   Also a silly point If you were to draw such sharp distinctions between ultraOrthodox and Modern Orthodox Judaism in a recognized Judaic Studies program they would not know what you are talking about A That statement is false because responsa in Orthodoxy does not work on the basis of someones synagogue affiliation B What is a Modern Orthodox responsa versus an ultraOrthodox responsa C In cases where things like hashgacha kosher certification etc are debated you will find in most cases that it is not a question of responsa If you know something about responsa literature in general which apparently you do not there are degrees of acceptance For example halav yisrael milk under rabbinical supervision during milking to ensure that it comes from a cow Most modernOrthodox Jews do not insist on it t on the basis of a responsa by Rabbi Moshe Feinstein who determined that American government supervision is sufficient Most ultraOrthodox Jews do insist on it They do not reject the responsa In fact Moshe Feinstein Reb Moshe as he was called was considered the leading halachic authority for the American ultraOrthodox community in the past fifty years They will say that the ruling is right BUT they want to be machmir more strict on themselves meaning more pious It is not a rejection It is simply being stricter Ovadya Yoseph said women could wear pants instead of skirts Would any of his daughters or daughtersinlaw be caught dead in pants No way They are machmir   You just cant make this stuff up Danny   I dunno I seem to be giving answers to everything you say and my answers are based on sources I am not making things up I am simply stating things that no matter how inconceivable it may be you do not know   Stop trying to remake the ultraOrthodox in your own image Its not good history Frankly I dont care what is on your resume It doesnt justify writing such nonsense  RK   Personal attacks I will say that your intellectual arrogance coupled with your apparent ignorance do not put you in a very good light   In my professional life I have researched and written extensively on this field developed relationships  both working and personal  with many of the people involved and worked on several important documentary films on the topic I think I have a sense of what NPOV is and a statement that the ultraOrthodox hate the nonultraOrthodox just doesnt make the mark    Is beating the shit out of nonOrthodox Jews an act of love Is calling them worse than Hitler an act of love Is accusing them of creating the Holocaust an act of tolerance Danny you can protest all you like but you obviously so immersed in an ultraOrthodox worldview that you cant see the forest for the trees This is violent hatespeech and it frightens me to see an educuated person making apologetics for it RK   Then it must frighten you even more knowing that I was actually there and on one occasion actually hit Why Because I do not feel the same antagonism that you do Because I see some distasteful remarks in a certain context You say in your diatribe that you want everyone to sit together and sing a Shlomo Carlebach niggun Just answer me this though Would Reb Shloime have davened in a shul without a mehitza   Oh and haredi does not mean trembling as you originally wrote at the top of the article In fact that was kind of funny You were apparently confused with the film Trembling Before God which</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120283</th>\n",
       "      <td>My apologies  Im English I watch cricket I know nothing Maybe I was thinking of the time he spent in the Army or maybe I was thinking of Elvis or something Im glad the page got improved</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128532</th>\n",
       "      <td>Someone wrote More recognizable perhaps is a type of what is generally called rock and roll called folk rock or simply folk which included performers such as Joan Baez Bob Dylan Simon and Garfunkel The Mamas and the Papas and many others   Ive tried to clarify this Folk rock is used very specifically and is typically far more recognised by instrumentation than form Many folk musicians of the s Tom Paxton Phil Ochs etc sang new topical material which distinguished them from traditional folk musicians but in the folk idiom acoustic instruments traditional arrangements and often traditional melodies  Re the comment about marketers in the first paragraph If language reflects common usage what is now called folk music has as much right to the name as any other form Gareth Owen  To the latter fair enough but does the first paragraph actually imply otherwise LMS  I like the page in general but wonder if the following is unnecessarily cynical implying as it does a financial rather than artistic incentive to change musical styles Some of these performers of which Joan Baez is an excellent example began their commercial music careers performing traditional music in a traditional idiom but soon transformed their style and accompaniment to suit popular tastes  Ya know I agree but I dont know how to change it right off Anyone else want to give it a stab LMS  The deletions are merely of things that seemed redundant Additions may solve the problem of tone mentioned above One bit of the original puzzles me so I corrected the grammar but left it inbut what does unrecognizable to its source actually mean  I like the new additionslots of good new information here I added some more The problem now is that the article is rambling and disorganized and I am probably not the best person to organize and clarify it BTW using the word purist without the quotes makes it sound as if the authors of the article are not purists which we dont want to imply  See neutral point of view LMS  Perhaps someone who knows the facts  could add in Skiffle music from whence the Beatles sprang which was evidently a British folk form in the s  Certainly the Beatles stole er utilised many folk forms in their music</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              comment  \\\n",
       "rev_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "37675                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      This is not creative  Those are the dictionary definitions of the terms insurance and ensurance as properly applied to destruction  If you dont understand that fine legitimate criticism Ill write up three man cell and bounty hunter and then it will be easy to understand why ensured and insured are different  and why both differ from assured  The sentence you quote is absolutely neutral  You just arent familiar with the underlying theory of strikeback eg submarines as employed in nuclear warfare guiding the insurance nor likely the three man cell structure that kept the IRA from being broken by the British  If thats my fault fine I can fix that to explain  But theres nothing personal or creative about it  Im tired of arguing with you  Re the other article multiparty turns up plenty and there is more use of mutually than mutual  If I were to apply your standard Id be moving Mutual Assured Destruction to talk for not appealing to a Reagan voters biases about its effectiveness and for dropping the ly  There is a double standard in your edits  If it comes from some US history book like peace movement or MAD as defined in  you like it even if the definition is totally useless in  and only of historical interest    If it makes any evenobvious connection or implication from the language chosen in multiple professionspecific terms you consider it somehow nonneutral  Gandhi thinks eye for an eye describes riots death penalty and war all at once but you dont  What do you know that Gandhi doesnt  Guess what  reality is not neutral  Current use of terms is slightly more controversial  Neutrality requires negotiation and some willingness to learn  This is your problem not mine  You may dislike the writing fine that can be fixed  But disregarding fundamental axioms of philosphy with names that recur in multiple phrases or failing to make critical distinctions like insurance versus assurance versus ensurance which are made in one quote by an Air Force general in an incontext quote is just a disservice to the reader  If someone comes here to research a topic like MAD they want some context beyond history  If this is a history book fine its a history book  But that wasnt what it was claimed to be    \n",
       "44816                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               the term standard model is itself less NPOV than I think wed prefer   if its newage speak then a lot of oldage people speak it  Karl Popper the Pope etc  heres Karl Poppers view of this   The clearest title for this article would be particle physics cosmology  but as I say that would require broader treatment of issues like the Anthropic Principle cognitive bias beyond the particle physics zoo etc   as to accelerators its clear that while they are in use someone is still looking for particles  So this is not yet a settled cosmology so certain that we abandon the search nor is it an arbitrary foundation ontology as you suggest not subject to question   \n",
       "49851                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     True or false the situation as of March  was such  A Saudi proposal of Land for Peace AND recognition by ALL arab countries was made The day the proposal was to be made formal by the Arab League was the day the Israelis under the command of Ariel Sharon began the invasion of the Palestinian selfrule areas userArab   \n",
       "89320                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Next maybe you could work on being less condescending with your suggestions about reading the naming conventions and FDL both of which I read quite a while ago thanks I really liked the bit where you were explaining why you had no interest in fixing things I complained about because you felt insulted yet you were being extremely insulting at the time With any luck you can learn to be less of a jerk GregLindahl          \n",
       "93890                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             This page will need disambiguation    \n",
       "102817                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Important note for all sysops There is a bug in the administrative move feature that truncates the moved history and changes the edit times  Please do not use this feature until this bug is fixed More information can be found in the talk of  and  Thank you    \n",
       "103624                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               I removed the following  All names of early Polish rulers are ficticious and therefore this index naming Oda von Haldensleben and her husband Dagome records for the first time rulers of the Polanen tribe Therefore it is indicated as being the first document of the later developing land named Poland  This is quite a comment All names are fictitious It deserves at least some backing    \n",
       "111032  If you ever claimed in a Judaic studies program that ultraOrthodox Jews dont have rabbis or dont have synagogues you would be laughed out of the room   I am beginning to see the problem you have You see you do not know how to read what other people say without attaching your personal bias to it Never once did I say that ultraOrthodox Jews have no rabbis or synagogues I DID say that the role of the rabbi and synagogue in ultraOrthodox Judaism is minimal when compared with say Conservative Judaism They are not clergy in the traditional Western sense of the word That is a fact As for synagogues they exist but they are not essential Minyan a quorum of ten adult males in ultraOrthodox law is essential You can have a minyan without a synagogue but a synagogue without a minyan is an empty building You can laugh all you want but it doesnt change the facts It may seem strange to you but take the statement to anyone who actually knows something I want to know who laughs then   If you ever claimed in a recognized Judaica studies program that a significant number of ultraOrthodox rabbis accept and follow Modern Orthodox responsa instead of their own people would look at you as if you had two heads   Also a silly point If you were to draw such sharp distinctions between ultraOrthodox and Modern Orthodox Judaism in a recognized Judaic Studies program they would not know what you are talking about A That statement is false because responsa in Orthodoxy does not work on the basis of someones synagogue affiliation B What is a Modern Orthodox responsa versus an ultraOrthodox responsa C In cases where things like hashgacha kosher certification etc are debated you will find in most cases that it is not a question of responsa If you know something about responsa literature in general which apparently you do not there are degrees of acceptance For example halav yisrael milk under rabbinical supervision during milking to ensure that it comes from a cow Most modernOrthodox Jews do not insist on it t on the basis of a responsa by Rabbi Moshe Feinstein who determined that American government supervision is sufficient Most ultraOrthodox Jews do insist on it They do not reject the responsa In fact Moshe Feinstein Reb Moshe as he was called was considered the leading halachic authority for the American ultraOrthodox community in the past fifty years They will say that the ruling is right BUT they want to be machmir more strict on themselves meaning more pious It is not a rejection It is simply being stricter Ovadya Yoseph said women could wear pants instead of skirts Would any of his daughters or daughtersinlaw be caught dead in pants No way They are machmir   You just cant make this stuff up Danny   I dunno I seem to be giving answers to everything you say and my answers are based on sources I am not making things up I am simply stating things that no matter how inconceivable it may be you do not know   Stop trying to remake the ultraOrthodox in your own image Its not good history Frankly I dont care what is on your resume It doesnt justify writing such nonsense  RK   Personal attacks I will say that your intellectual arrogance coupled with your apparent ignorance do not put you in a very good light   In my professional life I have researched and written extensively on this field developed relationships  both working and personal  with many of the people involved and worked on several important documentary films on the topic I think I have a sense of what NPOV is and a statement that the ultraOrthodox hate the nonultraOrthodox just doesnt make the mark    Is beating the shit out of nonOrthodox Jews an act of love Is calling them worse than Hitler an act of love Is accusing them of creating the Holocaust an act of tolerance Danny you can protest all you like but you obviously so immersed in an ultraOrthodox worldview that you cant see the forest for the trees This is violent hatespeech and it frightens me to see an educuated person making apologetics for it RK   Then it must frighten you even more knowing that I was actually there and on one occasion actually hit Why Because I do not feel the same antagonism that you do Because I see some distasteful remarks in a certain context You say in your diatribe that you want everyone to sit together and sing a Shlomo Carlebach niggun Just answer me this though Would Reb Shloime have davened in a shul without a mehitza   Oh and haredi does not mean trembling as you originally wrote at the top of the article In fact that was kind of funny You were apparently confused with the film Trembling Before God which    \n",
       "120283                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     My apologies  Im English I watch cricket I know nothing Maybe I was thinking of the time he spent in the Army or maybe I was thinking of Elvis or something Im glad the page got improved    \n",
       "128532                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Someone wrote More recognizable perhaps is a type of what is generally called rock and roll called folk rock or simply folk which included performers such as Joan Baez Bob Dylan Simon and Garfunkel The Mamas and the Papas and many others   Ive tried to clarify this Folk rock is used very specifically and is typically far more recognised by instrumentation than form Many folk musicians of the s Tom Paxton Phil Ochs etc sang new topical material which distinguished them from traditional folk musicians but in the folk idiom acoustic instruments traditional arrangements and often traditional melodies  Re the comment about marketers in the first paragraph If language reflects common usage what is now called folk music has as much right to the name as any other form Gareth Owen  To the latter fair enough but does the first paragraph actually imply otherwise LMS  I like the page in general but wonder if the following is unnecessarily cynical implying as it does a financial rather than artistic incentive to change musical styles Some of these performers of which Joan Baez is an excellent example began their commercial music careers performing traditional music in a traditional idiom but soon transformed their style and accompaniment to suit popular tastes  Ya know I agree but I dont know how to change it right off Anyone else want to give it a stab LMS  The deletions are merely of things that seemed redundant Additions may solve the problem of tone mentioned above One bit of the original puzzles me so I corrected the grammar but left it inbut what does unrecognizable to its source actually mean  I like the new additionslots of good new information here I added some more The problem now is that the article is rambling and disorganized and I am probably not the best person to organize and clarify it BTW using the word purist without the quotes makes it sound as if the authors of the article are not purists which we dont want to imply  See neutral point of view LMS  Perhaps someone who knows the facts  could add in Skiffle music from whence the Beatles sprang which was evidently a British folk form in the s  Certainly the Beatles stole er utilised many folk forms in their music    \n",
       "\n",
       "        year  logged_in       ns  sample  split  attack  \n",
       "rev_id                                                   \n",
       "37675   2002      False  article  random  train   False  \n",
       "44816   2002      False  article  random  train   False  \n",
       "49851   2002      False  article  random  train   False  \n",
       "89320   2002       True  article  random    dev   False  \n",
       "93890   2002       True  article  random  train   False  \n",
       "102817  2002       True     user  random  train   False  \n",
       "103624  2002       True  article  random  train   False  \n",
       "111032  2002       True  article  random    dev   False  \n",
       "120283  2002       True  article  random    dev   False  \n",
       "128532  2002       True  article  random  train   False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the clean data\n",
    "pd.set_option('display.max_colwidth', 10000)\n",
    "comments.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To validate if nulls are present in data and clean them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check if any value is null\n",
    "annotations.isnull().values.any()\n",
    "comments.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>115864.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2009.224306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.900431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                year\n",
       "count  115864.000000\n",
       "mean     2009.224306\n",
       "std         2.900431\n",
       "min      2001.000000\n",
       "25%      2007.000000\n",
       "50%      2009.000000\n",
       "75%      2011.000000\n",
       "max      2016.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 115864 entries, 37675 to 699897151\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   comment    115864 non-null  object\n",
      " 1   year       115864 non-null  int64 \n",
      " 2   logged_in  115864 non-null  bool  \n",
      " 3   ns         115864 non-null  object\n",
      " 4   sample     115864 non-null  object\n",
      " 5   split      115864 non-null  object\n",
      " 6   attack     115864 non-null  bool  \n",
      "dtypes: bool(2), int64(1), object(4)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "source": [
    "comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    107190\n",
       "True       8674\n",
       "Name: attack, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shows that classes are imbalanced\n",
    "comments['attack'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#displays the imbalance in the data\n",
    "ax = sns.countplot(x=\"attack\", hue=\"attack\",data=comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority(attack = False) and minority(attack = True) class\n",
    "majority = comments[comments.attack==0]\n",
    "minority = comments[comments.attack==1]\n",
    " \n",
    "# Upsample minority class\n",
    "minority_upsampled = resample(minority, \n",
    "                                 replace=True,     # Do resampling with replacement\n",
    "                                 n_samples=107190,    # Number same as majority class to ensure they balance\n",
    "                                 random_state=11)\n",
    " \n",
    "# Combine majority class with upsampled minority class to generate dataframe with balanced class values\n",
    "upsampled = pd.concat([majority, minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "upsampled.attack.value_counts()\n",
    "# Reset to the comments dataframe\n",
    "comments = upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: Using Train and Test split based on the column value \n",
    "(Consider only Comment as Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and Test split\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "X_train = train_comments['comment']\n",
    "y_train = train_comments['attack']\n",
    "X_test = test_comments['comment']\n",
    "y_test = test_comments['attack']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model : Using Tf-idf Vectorizer  and Linear SVC (Selecting the model - Final)\n",
    "For the Vectorizer : used cleaned comments and further remove the stop words.\n",
    "Hyper Tuned parameters like ngram range\n",
    "Result Accuracy = 0.96\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.96      0.88     21385\n",
      "        True       0.96      0.77      0.85     22123\n",
      "\n",
      "    accuracy                           0.87     43508\n",
      "   macro avg       0.88      0.87      0.86     43508\n",
      "weighted avg       0.88      0.87      0.86     43508\n",
      "\n",
      "Accuracy: 0.8653351107842235\n"
     ]
    }
   ],
   "source": [
    "''' For imbalanced data: Performance is:\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       False       0.97      0.99      0.98     21385\n",
    "        True       0.85      0.63      0.72      1793\n",
    "\n",
    "    accuracy                           0.96     23178\n",
    "   macro avg       0.91      0.81      0.85     23178\n",
    "weighted avg       0.96      0.96      0.96     23178\n",
    "\n",
    "Accuracy: 0.9626801277073087'''\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 10000, ngram_range = (1,1),norm = 'l2',analyzer ='word', lowercase = True, stop_words ={'english'}, strip_accents = 'ascii')),\n",
    "    ('clf', LinearSVC(random_state=87,C=1.5,max_iter = 1871))\n",
    "])\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "met= metrics.classification_report(y_test, y_predict)\n",
    "print(met)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20615   770]\n",
      " [ 5089 17034]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEGCAYAAACEgjUUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZxU1ZnG8d8DiKICggjKIiKiRk3EnUSJO6JRwR00ikvSakTFZGZcMDExyahxS8hEE1QU96BGRQdEJKhRQUFlQAQFUbGhwyKLCAh09zt/1G0soJfqpprurnq++ZxP3Tr33HtPzeBbp9976lxFBGZmltsa1XUHzMys9jnYm5nlAQd7M7M84GBvZpYHHOzNzPJAk7ruQEXWLZ7jaUK2iWbte9Z1F6weKl47T5t7jurEnK3a7L7Z19vSPLI3M8sD9XZkb2a2RZWW1HUPapWDvZkZQElxXfegVjmNY2YGRJRmXCojqZOk8ZJmSJou6eqkvrWksZJmJa+tknpJGiJptqSpkg5MO9eApP0sSQPS6g+SNC05ZoikKu8hONibmQGUlmZeKlcM/CIivgP0AK6QtA9wHTAuIroB45L3ACcC3ZJSANwLqS8H4CbgMOBQ4KayL4ikTUHacb2r6pSDvZkZQJRmXio7TURRRLyXbK8AZgAdgD7A8KTZcKBvst0HeDhSJgI7SNoFOAEYGxFLImIpMBbonexrERETIrW42cNp56qQc/ZmZlCtG7SSCkiNrMsMjYih5bTbDTgAeBtoFxFFkPpCkNQ2adYB+CLtsMKkrrL6wnLqK+Vgb2YGVY7YN2iaCuybBPd0krYHngEGRcRXlaTVy9sRNaivlNM4ZmZAlBRnXKoiaStSgf6xiPhHUr0gScGQvC5M6guBTmmHdwTmV1HfsZz6SjnYm5lB1m7QJjNjHgBmRMRdabtGAmUzagYAz6fVX5DMyukBLE/SPWOAXpJaJTdmewFjkn0rJPVIrnVB2rkq5DSOmRlUK41ThcOB84FpkqYkdTcAtwIjJF0CzAXOSvaNAk4CZgOrgIsAImKJpN8Ck5J2N0fEkmT7cuAhoBkwOimVUn19UpXXxrHyeG0cK0821sZZM/O1jGPO1nsf2eDWxvHI3swMsjmyr5cc7M3MIOeXS3CwNzODTH4Z26A52JuZARFe9dLMLPc5Z29mlgecxjEzywMe2ZuZ5YGSdXXdg1rlYG9mBk7jmJnlBadxzMzygEf2ZmZ5wMHezCz3hW/QmpnlAefszczygNM4ZmZ5wCN7M7M84JG9mVkeyPGRvR84bmYGUFyceamCpGGSFkr6IK3u75KmJOWzsufTStpN0uq0fX9NO+YgSdMkzZY0JHnAOJJaSxoraVby2qqqPjnYm5lBamSfaanaQ0DvDU4fcU5EdI+I7sAzwD/Sdn9Sti8iLkurvxcoALolpeyc1wHjIqIbMC55XykHezMzSOXsMy1ViIjXgSXl7UtG52cDT1R2Dkm7AC0iYkJEBPAw0DfZ3QcYnmwPT6uvkIO9mRlUa2QvqUDS5LRSUI0r9QQWRMSstLoukt6X9JqknkldB6AwrU1hUgfQLiKKAJLXtlVd1DdozcygWrNxImIoMLSGV+rPhqP6ImDXiPhS0kHAc5L2BVTepWt4TQd7MzNgi8zGkdQEOB04aP1lI9YAa5LtdyV9AuxJaiTfMe3wjsD8ZHuBpF0ioihJ9yys6tpO45iZQVZn41TiOGBmRKxPz0jaSVLjZHt3Ujdi5yTpmRWSeiR5/guA55PDRgIDku0BafUVcrA3MwOIyLxUQdITwARgL0mFki5JdvVj0xuzPwSmSvo/4Gngsogou7l7OXA/MBv4BBid1N8KHC9pFnB88r5STuOYmUFWf0EbEf0rqL+wnLpnSE3FLK/9ZGC/cuq/BI6tTp8c7M3MwMslmJnlhRxfLsHB3swMoKSkrntQqxzszczAaRwzs7zgYG9mlgecszczy31RWuOVCBoEB3szM3Aax8wsL3g2jplZHvDI3swsD+R4sPdCaFlWtGARFw28llPOLaDPeZfyyIjnNmkz5/MvOK/gGg446hQefPzprFx37dq1/OKXt3Di2RfT/6eDmFe0YMN+/Xshhxx3WtauZ9Wz555dmTzp5fVlyeKZXHXlTzZo84ufX7Z+/5T3x7Fm9Vxatdphs67btGlTHn/sXmZ++AZvvfECnTunVsw97tievD1xNO+/9wpvTxzN0UcdvlnXyQlZXAitPnKwz7ImjRvzn1f+lBceH8rjQ+/myX+8yCeffr5Bm5YtmnPdNZdxYf8zqn3+eUULuHDgf21S/48XX6ZF8+0ZPWIY55/Tl7vuGbbB/tuGDKVnj4OrfT3Ljo8//oSDD+nFwYf04tDDerNq1Wqee370Bm3uvOuv69vceOOtvP76RJYuXZbR+Tt37si4sU9tUn/xRf1ZunQ5e+9zBH8cch+3/PdgABZ/uYS+p13IAQcex8WXDOKhB/+0+R+yocviYwnro1oL9pL2lnRt8kT0PyXb36mt69UXO7VpzT577QHAdttty+6dO7Fg0ZcbtNmx1Q589zt70aTJplm0F8b8k34/uZozBlzBb/4whJIMbxr9818T6HPScQD0Oqonb787hUhGIONef4uO7Xema5fOm/PRLEuOPeYI5sz5nLlz51XY5pxz+vDk37/9q/Dcc09nwpsvMnnSy9zzl9to1Ciz/3RPPaUXjzyS+hJ45pn/5ZijjwBgypTpFCV//U2f/hHbbLMNTZs2relHyg2lkXlpgGol2Eu6FniS1GO13gEmJdtPSKryKei5Yl7RAmbM+oTv7btXRu0/+WwuL417jUf+eifPDP8LjRo14sWXx2d07MJFX7Jz2zYANGnSmO2325Zly79i1epvGPboU/zs4vNq/Dksu84+e8NAvrFmzbbhhF5H8Y9nRwGw9957cPZZp9LzyL4cfEgvSkpKOPfc0zO6VvsOO/NFYerhRiUlJSxf/hU77thqgzann/4jpkz5gLVr19bwE+WIkpLMSwNUWzdoLwH2jYh16ZWS7gKmU8FC+8lDewsA7rnzd/zkgnKXhG4QVq1azTWDf8e1V13K9tttl9Exb0+ewoczZ9PvkqsBWLNmDa2TnO1V19/MvPkLWFe8jqIFizhjwBUA/PjsPpz2o17rR/HpJPGXBx7h/HNOY9ttm2Xpk9nm2GqrrTjl5F4MvvGWCtucfHIv3poweX0K55ijj+DAA77LxAmp4N+s2TYsWrQYgKefup/ddtuVpk23YtdOHZg86WUA/vzn+xn+8AhSDzjaUPo/lX322ZNbfn8DJ/7o3Gx9xAYrGmh6JlO1FexLgfbA5xvV75LsK1f6Q3zXLZ7TMP9WAtYVFzNo8O/4Ua+jOb4aN74iglNPPI5rLr9ok31DbvkVkPprYfDv7+Sh//nDBvvbtW3DvxcuZue2O1FcXMLXK1fRskVzpk3/iLHj3+Cuex5gxdcrkcTWTZty7pmnbt6HtBrp3fto3n9/GgsXLq6wzTlnn7rByF8Sjzz6FINv3HSMdOZZqZu8nTt3ZNj9d3Ps8WdtsH9eYRGdOrZn3rwiGjduTMuWLViyZCkAHTrswtNPPcBFF1/NnDkb/6eahxpoeiZTtZWzHwSMkzRa0tCkvASMA66upWvWCxHBr275I7t37sSAfpn9qV2mx8HdGfvqG3yZjOiWf7WC+f9eUMVRKUcf0YPnR70CwMuv/ovDDtofSTx87x28/MxwXn5mOD8+uy8/veAcB/o61O+cvpWmcFq0aM4Pe/Zg5Mgx6+v+Of4NTj/tZHbaaUcAWrXagV137ZDR9V548WXOPz/1BXDGGT9i/KtvAtCyZQtGPv8wg2+8hbcmTK7px8ktUZp5aYBqZWQfES9J2hM4FOhAKl9fCEyKiIaZ8MrQ+1On88JL4+jWdbf1qZarLx1A0YJFAJxz2o9Y/OUSzrnkKr5euYpGjRrx6IjneP6xv9G1S2eu/OkFFAwaTGmUslWTJgz++c9ov3O7Kq97+skncP1vb+fEsy+mZYvm3P6bvLk10mA0a7YNxx37Qy7/2bXr6wp+ej4AQ+97BIC+fU5k7Cuvs2rV6vVtZsyYxa9+/QdGj3qCRo3EunXFXHXV4Epv8JYZ9uCTDH9oCDM/fIOlS5dx7o9/BsAVP7uIPbruxuAbBjH4hkEAnHhSfxZtNJkgr+T4yF7l5Xrrg4acxrHa06x9z7rugtVDxWvnbXpzoppW/qpfxjFnu5ufrPR6koYBJwMLI2K/pO7XwE+BRUmzGyJiVLLvelL3OkuAqyJiTFLfG/gT0Bi4PyJuTeq7kJoE0xp4Dzg/Iiq9w+559mZmkO00zkNA73Lq746I7kkpC/T7AP2AfZNj7pHUWFJj4C/AicA+QP+kLcBtybm6AUtJfVFUysHezAyyOs8+Il4HlmR45T7AkxGxJiI+BWaTSoEfCsyOiDnJqP1JoI9SU6yOAcp+Dj8c6FvVRRzszcxITb3MtEgqkDQ5rRRkeJmBkqZKGiap7AcPHYAv0toUJnUV1e8ILIuI4o3qK+Vgb2YG1RrZR8TQiDg4rQzN4Ar3Al2B7kARcGdSX17+P2pQXymvemlmBrU+Gyci1s+jlnQf8GLythDolNa0IzA/2S6vfjGwg6Qmyeg+vX2FPLI3M4NaXy5B0i5pb08DPki2RwL9JG2dzLLpxrfLzHST1EVSU1I3cUdGagrleODM5PgBwPNVXd8jezMzsvsMWklPAEcBbSQVAjcBR0nqTirl8hlwKUBETJc0AvgQKAauKPs9kqSBwBhSUy+HRcT05BLXAk9K+h3wPvBAlX3yPHtrSDzP3sqTjXn2K646OeOY03zIi5t9vS3NI3szM2iw69RnysHezAxyfrkEB3szM3CwNzPLB1HiNI6ZWe7zyN7MLPdlc+plfeRgb2YGHtmbmeWF3E7ZO9ibmQFEcW5Hewd7MzPwyN7MLB/4Bq2ZWT7wyN7MLPd5ZG9mlg88sjczy33rn+iaoxzszcyA8MjezCwPONibmeW+XB/Z+4HjZmakgn2mpSqShklaKOmDtLrbJc2UNFXSs5J2SOp3k7Ra0pSk/DXtmIMkTZM0W9IQSUrqW0saK2lW8tqqqj452JuZAVGijEsGHgJ6b1Q3FtgvIr4HfAxcn7bvk4jonpTL0urvBQqAbkkpO+d1wLiI6AaMS95XysHezIzsjuwj4nVgyUZ1L0esn/MzEehY2Tkk7QK0iIgJERHAw0DfZHcfYHiyPTytvkIO9mZmQJQq4yKpQNLktFJQzctdDIxOe99F0vuSXpPUM6nrABSmtSlM6gDaRUQRQPLatqoL+gatmRnVu0EbEUOBoTW5jqTBQDHwWFJVBOwaEV9KOgh4TtK+QHn5ohr/zNfB3swMiMgoF79ZJA0ATgaOTVIzRMQaYE2y/a6kT4A9SY3k01M9HYH5yfYCSbtERFGS7llY1bWdxjEzI7s5+/JI6g1cC5waEavS6neS1DjZ3p3Ujdg5SXpmhaQeySycC4Dnk8NGAgOS7QFp9RXyyN7MDCjNbJZNRiQ9ARwFtJFUCNxEavbN1sDYZAblxGTmzQ+BmyUVAyXAZRFRdnP3clIze5qRyvGX5flvBUZIugSYC5xVZZ+SvyTqnXWL59TPjlmdata+Z9WNLO8Ur5232ZH68wOPyzjmdH7vldrP+WSZR/ZmZqRm4+QyB3szM6CeJjmyptJgL2kF5U/1ERAR0aJWemVmtoXl9cg+IppvqY6YmdWlLTH1si5VK40jqS2wTdn7iJib9R6ZmdWBkizOxqmPMppnL+lUSbOAT4HXgM/Y8Ke+ZmYNWoQyLg1Rpj+q+i3QA/g4IroAxwJv1lqvzMy2sOqsjdMQZRrs10XEl0AjSY0iYjzQvRb7ZWa2RUVkXhqiTHP2yyRtD7wOPCZpIamFfMzMckJDHbFnKtNg3wf4BrgGOA9oCdxcW50yM9vSSkpze6mwjIJ9RKxMezu8woZmZg1UQ03PZCqjYL/Rj6uaAlsBK/2jKjPLFaUNdJZNpjId2W/w4ypJfYFDa6VHZmZ1oKFOqcxUjZJUEfEccEyW+2JmVmc8GweQdHra20bAwWzG47Ey0f+gQbV5emugVjx4cV13wXKU0zgpp6RtF5P6BW2frPfGzKyOeDZOyv0RscEvZiUdTgbPPTQzawgaaHYmY5l+lf05wzozswapNJRxaYiqWs/++8APgJ0k/TxtVwugcW12zMxsS8r32ThNge1JfSk0TytfAWfWbtfMzLac0mqUqkgaJmmhpA/S6lpLGitpVvLaKqmXpCGSZkuaKunAtGMGJO1nSRqQVn+QpGnJMUOUPMG8MlU9vOQ14DVJD0XE5xl8RjOzBinI6sj+IeB/gIfT6q4DxkXErZKuS95fC5wIdEvKYcC9wGGSWgM38e3sx3cljYyIpUmbAmAiMAroTRXLzmeas79f0g5lbyS1kjQmw2PNzOq94lDGpSoR8TqwZKPqPny73MxwoG9a/cORMhHYQdIuwAnA2IhYkgT4sUDvZF+LiJgQEUHqC6UvVcg02LeJiGVpH2Qp0DbDY83M6r1AGRdJBZImp5WCDC7RLiKKAJLXshjaAfgirV1hUldZfWE59ZXKdOplqaRdyx5DKGk3cn+mkpnlkUxy8WUiYigwNEuXLu9PhahBfaUyDfaDgTckvZa8/yGpfJGZWU7Ics6+PAsk7RIRRUkqpux3SoVAp7R2HYH5Sf1RG9W/mtR3LKd9pTJK40TES6RuEnwE/B34BbA6k2PNzBqCbM7GqcBIoGxGzQDg+bT6C5JZOT2A5UmaZwzQK7lH2groBYxJ9q2Q1COZhXNB2rkqlOnaOD8Brib1DTKF1PNoJ+DF0MwsR5RkcWQv6QlSo/I2kgpJzaq5FRgh6RJgLnBW0nwUcBIwG1gFXAQQEUsk/RaYlLS7OSLKbvpeTmrGTzNSs3AqnYkDmadxrgYOASZGxNGS9gZ+k+GxZmb1XjafShgR/SvYdWw5bQO4ooLzDAOGlVM/GdivOn3KNNh/ExHfSELS1hExU9Je1bmQmVl9Vlr7Ofs6lWmwL0zm2T8HjJW0lAxuCJiZNRS5Pr0w0ydVnZZs/lrSeFIPHH+p1nplZraFbcaN1wYh05H9eskSCmZmOaW06uVlGrRqB3szs1xUUtcdqGUO9mZmZHc2Tn3kYG9mhmfjmJnlBc/GMTPLA07jmJnlAU+9NDPLAyUe2ZuZ5T6P7M3M8oCDvZlZHsjg0bINmoO9mRke2ZuZ5QUvl2Bmlgc8z97MLA/kehonoweOm5nlumw9cFzSXpKmpJWvJA2S9GtJ89LqT0o75npJsyV9JOmEtPreSd1sSddtzufzyN7MjOytjRMRHwHdASQ1BuYBz5J6kPjdEXFHentJ+wD9gH2B9sArkvZMdv8FOB4oBCZJGhkRH9akXw72ZmbUWs7+WOCTiPhcFT8cpQ/wZESsAT6VNBs4NNk3OyLmAEh6Mmlbo2DvNI6ZGanZOJkWSQWSJqeVggpO2w94Iu39QElTJQ2T1Cqp6wB8kdamMKmrqL5GHOzNzIBSIuMSEUMj4uC0MnTj80lqCpwKPJVU3Qt0JZXiKQLuLGtaTneikvoacRrHzIxamY1zIvBeRCwAKHsFkHQf8GLythDolHZcR2B+sl1RfbV5ZG9mRmrInGnJUH/SUjiSdknbdxrwQbI9EugnaWtJXYBuwDvAJKCbpC7JXwn9krY14pG9mRnZHdlL2pbULJpL06r/IKk7qe+Lz8r2RcR0SSNI3XgtBq6IiJLkPAOBMUBjYFhETK9pnxzszcyAYmXvwYQRsQrYcaO68ytp/3vg9+XUjwJGZaNPDvZmZvgZtGZmeSHXl0twsDczIzX1Mpc52JuZ4TSOmVlecBrHzCwPlOT42N7B3swMj+zNzPJCeGRvZpb7PLK3arvnjftYvXI1pSWllJaUcO0pv9hgf/uuHbjijqvZfd+uPHHHI4wc+txmX7NJ0yZcedc17P7dPfh66VfcNfB2FhUuZI/9u3HpLVcAIIkRf3yCd8ZM3OzrWfXdNPIdXv+4iNbbbc0zl/feZP9Db81k1LS5AJSUlvLp4hWM/49Tadls6xpfc21xCTc+9w4zipbSsllTbjvz+3TYYbv1+4uWr+T0e8Zw2ZH7MOAHe9f4OrnAUy+tRn7dbzArlq4od9/Xy75m2E1DOfSEHtU+704d2zLwjqu5qd/gDeqPPed4Vi7/miuPvJTDT+nJj68bwN0Db2fuR59z7Sk/p7SklB3atuLO0X9i8ivvUFqS6+OY+ufU/bvQ75Bu3Pjc2+Xuv/AHe3NhEnBf+2g+j779ccaBft6ylfzq+Xd4YMDRG9Q/+/6ntGi2FS9ceRIvfTCXP70ylT+c+f31++8YM4XD99i5hp8ot+R2qHewrxNffbmcr75czkHHHLLJvp6nHcVJF55Mk62aMGvKx9x/418pLa06MB9y/GGM+GNqgb0Jo97kkptT6y+t/Wbt+jZNt25K5Pq/6HrsoM47MW/Zyozajp4+l977fbu67f9O/ZzH35nFupJSvtuhNTecdCCNG1W9aO2rH83jsiP3BeC4fTpy6+j3iAgk8c+Z8+jQanuabdW4Zh8oxxTneLj3Ese1IIBfPnozt714F8f1P6HK9mU67NGRw08+ghvPuJb/PGkQpaWl9Ox7ZEbHtt55RxbPXwxAaUkpq1aspHmr5gB0674nd4/9H+4cM4Shg+/xqL6eW72umLdm/5vjvtMRgDmLvmLM9Lk8dNExjLi0F40aaX26pyoLV6xm55bbAtCkUSO232Yrlq1ey+q1xTz05kwuO3KfWvscDU1U438N0RYf2Uu6KCIerGBfAVAAcEDr77H79p23aN+y5cbTr2XpwiW02LElv3r0ZuZ9UsiMd6pemfS7h+/P7t/tyq0jUw+wabpNU75avByA//zb9bTt1I4mTZvQpv1O3D7qjwCMevAFxj81jvKeb1k2ip815WOuOX4gHfboyMA7B/H+q++ybs26LH1ay7bXP55P9047rk/hvPPpAmYULeW8+18BYE1xCa23Te275u9vMm/ZSopLSilavoqz//YyAOce1o2+3buUG5YE3PvqB5zXY0+2bbrVlvhIDUKuD4HqIo3zG6DcYJ882msowJmdT22YX5/A0oVLgFS65p0xE+nWvVtGwV6CV58ez+N/eHiTfbdfegtQcc7+y6LFtGnfhiX//pJGjRuxbfPt+HrZhvcM5s0uZM3qb9h1z858Mm12TT+e1bKXPviC3vvtuv59AKfsvxtXHfu9Tdrefc7hQMU5+3bNm/Hv5ato12JbiktL+fqbdbRs1pRp85YwdkYhf3zl/1jxzToaSWzdpDH9Du1Wq5+tPmuoI/ZM1UoaJ3mgbnllGtCuNq5ZX2zdbGu22a7Z+u39f9iduR9l9if3tDen8v2TfkCLHVsCsH3L7WnTYaeMjp38yjscdcYxAHz/pMP54K2pALTt1I5GjVP/b27TYSfa796BhYULKjyP1a0V36zl3c8XcfRe3z5X+tAubRk7o5AlK78BYPnqNczPMPd/5F7teWHqZwC88mEhh3RpiyQevOgYRl99MqOvPpnzDuvGJUfsndeBHlIj+0xLQ1RbI/t2wAnA0o3qBbxVS9esF1q22YH/GnoDAI2bNOZfz7/GlNfeo9d5qal2Lz/2EjvstAO3vXAXzbbfligt5UcXn8qg466gcNYXPHHHo/zykd/QqFEjiouLuf+Xf2PxvEVVXnfc38dy1d0/58+v/Y2vl63g7oG3A7D3wd/htJ/9kuJ1xUQE99341wpnCVntuu6ZCUz+fBHLVq2h190vcPlR+1Kc3D856+A9APjnzHl8v2s7mjX99j/Nrju1ZODR+3HZo68TETRp3IjrTzyQ9mlTKCty2gG7M/jZtznlz6No0awpt51R/Rlg+aIkx2cvKGrhA0p6AHgwIt4oZ9/jEXFuVedoyGkcqz2P/Pf+dd0Fq4eanffbTW9aVdO5nU/LOOY8/vmzm329La1W0jgRcUl5gT7ZV2WgNzPb0rI5G0fSZ5KmSZoiaXJS11rSWEmzktdWSb0kDZE0O0l3H5h2ngFJ+1mSBmzO5/PUSzMzaiVnf3REdI+Ig5P31wHjIqIbMC55D3Ai0C0pBcC9kPpyAG4CDgMOBW4q+4KoCQd7MzNSyyVkWmqoDzA82R4O9E2rfzhSJgI7SNqF1H3PsRGxJCKWAmOBTdfZyJCDvZkZ1UvjSCqQNDmtFGxyOnhZ0rtp+9pFRBFA8to2qe8AfJF2bGFSV1F9jXi5BDMzqjcbJ/03QRU4PCLmS2oLjJU0s5K25d3sjUrqa8QjezMzspvGiYj5yetC4FlSOfcFSXqG5HVh0rwQ6JR2eEdgfiX1NeJgb2ZG9m7QStpOUvOybaAX8AEwEiibUTMAeD7ZHglckMzK6QEsT9I8Y4BeklolN2Z7JXU14jSOmRlZXS6hHfBssl5VE+DxiHhJ0iRghKRLgLnAWUn7UcBJwGxgFXARQEQskfRbYFLS7uaIWFLTTjnYm5mRvYeXRMQcYJNf/0XEl8Cx5dQHcEUF5xoGDMtGvxzszcyA2lhNoD5xsDczA0pyfNVLB3szM/wMWjOzvOA0jplZHvDI3swsD+T6k6oc7M3MyP2HlzjYm5nhNI6ZWV5wsDczywOejWNmlgc8sjczywOejWNmlgdKohpPl22AHOzNzHDO3swsLzhnb2aWB5yzNzPLA6VO45iZ5T6P7M3M8kCuz8ZpVNcdMDOrD0ojMi6VkdRJ0nhJMyRNl3R1Uv9rSfMkTUnKSWnHXC9ptqSPJJ2QVt87qZst6brN+Xwe2ZuZkdU0TjHwi4h4T1Jz4F1JY5N9d0fEHemNJe0D9AP2BdoDr0jaM9n9F+B4oBCYJGlkRHxYk0452JuZkb0btBFRBBQl2yskzQA6VHJIH+DJiFgDfCppNnBosm92RMwBkPRk0rZGwd5pHDMzUiP7TP8nqUDS5LRSUN45Je0GHAC8nVQNlDRV0jBJrZK6DsAXaYcVJnUV1deIg72ZGVASJRmXiBgaEQenlaEbn0/S9sAzwKCI+Aq4F+gKdCc18r+zrGk53YlK6mvEaRwzM7K7XIKkrUgF+sci4h/J+Rek7b8PeDF5WzeJH/4AAARkSURBVAh0Sju8IzA/2a6ovto8sjczI7VcQqalMpIEPADMiIi70up3SWt2GvBBsj0S6Cdpa0ldgG7AO8AkoJukLpKakrqJO7Kmn88jezMzsjqyPxw4H5gmaUpSdwPQX1J3UqmYz4BLk+tOlzSC1I3XYuCKiCgBkDQQGAM0BoZFxPSadsrB3syMrM7GeYPy8+2jKjnm98Dvy6kfVdlx1eFgb2aGl0swM8sLub5cgoO9mRl+eImZWV7wEsdmZnnAI3szszzgxxKameUBj+zNzPKAZ+OYmeUB36A1M8sDTuOYmeUB/4LWzCwPeGRvZpYHcj1nr1z/NssFkgrKexKO5Tf/u7Dq8MNLGoZyn29pec//LixjDvZmZnnAwd7MLA842DcMzstaefzvwjLmG7RmZnnAI3szszzgYG9mlgcc7Os5Sb0lfSRptqTr6ro/VvckDZO0UNIHdd0Xazgc7OsxSY2BvwAnAvsA/SXtU7e9snrgIaB3XXfCGhYH+/rtUGB2RMyJiLXAk0CfOu6T1bGIeB1YUtf9sIbFwb5+6wB8kfa+MKkzM6sWB/v6TeXUea6smVWbg339Vgh0SnvfEZhfR30xswbMwb5+mwR0k9RFUlOgHzCyjvtkZg2Qg309FhHFwEBgDDADGBER0+u2V1bXJD0BTAD2klQo6ZK67pPVf14uwcwsD3hkb2aWBxzszczygIO9mVkecLA3M8sDDvZmZnnAwd7qPUlfJ6/tJT1dRdtBkrat5vmPkvTi5vTRrL5zsLc6kazoWS0RMT8izqyi2SCgWsHeLB842FvWSdpN0kxJwyVNlfS0pG0lfSbpV5LeAM6S1FXSS5LelfQvSXsnx3eRNEHSJEm/3ei8HyTbjSXdIWlaco0rJV0FtAfGSxqftOuVnOs9SU9J2j6p75308Q3g9C39fyOzLc3B3mrLXsDQiPge8BXws6T+m4g4IiKeJPXA7Csj4iDgP4B7kjZ/Au6NiEOAf1dw/gKgC3BAco3HImIIqbWDjo6IoyW1AW4EjouIA4HJwM8lbQPcB5wC9AR2zuonN6uHmtR1ByxnfRERbybbjwJXJdt/B0hG2D8AnpLWL+65dfJ6OHBGsv0IcFs55z8O+GuypAQRUd767j1IPfTlzeQaTUktM7A38GlEzEr68iipLw+znOVgb7Vl43U4yt6vTF4bAcsionuGx29MGbYZGxH9N6iUumdwrFlOcRrHasuukr6fbPcH3kjfGRFfAZ9KOgtAKfsnu98ktcInwHkVnP9l4DJJTZLjWyf1K4DmyfZE4HBJeyRttpW0JzAT6CKpa1r/zHKag73VlhnAAElTgdbAveW0OQ+4RNL/AdP59pGLVwNXSJoEtKzg/PcDc4GpyfHnJvVDgdGSxkfEIuBC4ImkHxOBvSPiG1Jpm/9NbtB+vnkf1az+86qXlnWSdgNejIj96rgrZpbwyN7MLA94ZG9mlgc8sjczywMO9mZmecDB3swsDzjYm5nlAQd7M7M88P9Z+yxVTc2cfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, clf.predict(X_test), labels=[False,True]))\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, clf.predict(X_test), labels=[False, True]), annot=True)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: Train and Test split by randomizing/shuffling and stratification\n",
    "Stratification ensures to preserving the percentage of samples for each class.\n",
    "Comment is considered as Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Take the comments as X\n",
    "X_df = comments.comment\n",
    "# Take the attack as class value\n",
    "y_df = comments[\"attack\"]\n",
    "#Split into test-train data, ensuring shuffling and stratification\n",
    "X_train_df, X_test_df,y_train_df, y_test_df = train_test_split(X_df,y_df,test_size=0.3,random_state = 131, shuffle = True, stratify=y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.95      0.97     32157\n",
      "        True       0.95      0.99      0.97     32157\n",
      "\n",
      "    accuracy                           0.97     64314\n",
      "   macro avg       0.97      0.97      0.97     64314\n",
      "weighted avg       0.97      0.97      0.97     64314\n",
      "\n",
      "Accuracy: 0.9687315359019809\n"
     ]
    }
   ],
   "source": [
    "''' For imbalanced data: Performance is:\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "       False       0.97      0.99      0.98     32158\n",
    "        True       0.83      0.66      0.73      2602\n",
    "\n",
    "    accuracy                           0.96     34760\n",
    "   macro avg       0.90      0.82      0.86     34760\n",
    "weighted avg       0.96      0.96      0.96     34760\n",
    "\n",
    "Accuracy: 0.9643268124280783'''\n",
    "\n",
    "# Model Generation for balanced dataset\n",
    "\n",
    "clf_4 = Pipeline([('tfidf', TfidfVectorizer(max_features = 10000, ngram_range = (1,1),norm = 'l2',analyzer ='word', lowercase = True, stop_words ={'english'}, strip_accents = 'ascii')),\n",
    "    ('clf', LinearSVC(random_state=87,C=1.5,max_iter = 1871))\n",
    "])\n",
    "clf_4 = clf_4.fit(X_train_df, y_train_df)\n",
    "y_predict_4 = clf_4.predict(X_test_df)\n",
    "met_4 = metrics.classification_report(y_test_df, y_predict_4)\n",
    "print(met_4)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_df, y_predict_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20658   727]\n",
      " [  165 21958]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(test_comments['attack'], clf_4.predict(test_comments['comment']), labels=[False,True]))\n",
    "sns.heatmap(metrics.confusion_matrix(test_comments['attack'], clf_4.predict(test_comments['comment']), labels=[False, True]), annot=True)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nice comment\n",
    "clf_4.predict(['Thanks for you contribution, you did a great job!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_4.predict(['You are a good person!!!!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correctly classify nasty comment\n",
    "clf_4.predict(['People as stupid as you should not edit Wikipedia!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_4.predict(['You are an idiot!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report:\n",
    "\n",
    "Using Python 3 version\n",
    "\n",
    "## Step 1: Analyzing the dataset:\n",
    "The dataset contains various columns/features like - comment, year, logged_in, ns,sample, split\n",
    "Class = attack (Type= boolean, False = not a personal attack, good comment; True = Personal attack, bad comment)\n",
    "\n",
    "## Step 2: Data Cleaning:\n",
    "The comment is user-defined. Thus, will have a lot of slang, punctuations, typos, extra spaces, etc.\n",
    "Thus, we need to clean the data. 'Comment' feature is the most important feature to decide if it's a personal attack or not.\n",
    "\n",
    "**Following cleaning steps are carried out:**\n",
    "1. Removing NewLine Token\n",
    "2. Removing TabToken \n",
    "3. Removing Punctuations\n",
    "4. Removing Stop words (done on vectorizer)\n",
    "5. Removing english accent words.\n",
    "6. Check for NaN or None (No null or NaN found)\n",
    "\n",
    "All these are included in the final code.\n",
    "\n",
    "## Step 3: Feature Selection and Feature Extraction\n",
    "The most important Feature is 'comment'. Apart from comment I considered year and ns features too. However, they didn't contribute much to improve the performance and took a lot of run time. Thus, in my final code model, I have considered **'comment' as the only feature.**\n",
    "\n",
    "To use 'attack' information from different annotators I tried the following:\n",
    "1. Average and use threshold = 0.5\n",
    "2. Median and use threshold = 0.5 (Doesn't lead to significant improvement)\n",
    "3. Average and use threshold = 0.6 (Choosen)\n",
    "\n",
    "## Step 4: Optimizations\n",
    "I have included few optimizations -removing stop words and accents while performing Tf-idf vectorization. This ensures more cleaner data and TFIDF Vectorizer is more better as stop words are removed.\n",
    "\n",
    "## Step 5: Preparing Train and Test data\n",
    "\n",
    "**Part 1: Handling imbalanced data**\n",
    "In Step 1, I found out that the data is imbalanced.\n",
    "False    107190\n",
    "True       8674\n",
    "Name: attack, dtype: int64\n",
    "\n",
    "Thus, to get better performance, before applying the models, we make the data balanced(Used: from sklearn.utils import resample). This is very crucial as it will avoid model to be overfit or underfit.\n",
    "\n",
    "**Part 2: Randomizing and Stratifing the data**\n",
    "1. I tried to build model using the test and train label dataset. However, found that random split works better.\n",
    "2. Holdout Estimate method: This splits data into 70-30% (User defined)split. This is good as it is shuffled and stratified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Try Models\n",
    "\n",
    "Various Models were tried for combinations of different test-train datasets. (Without balancing the data)\n",
    "\n",
    "\n",
    "**Given Model/BaseLine**\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_features = 10000, ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer(norm = 'l2')),\n",
    "    ('clf', DecisionTreeClassifier(random_state = 123)),\n",
    "])\n",
    "clf = clf.fit(train_comments['comment'], train_comments['attack'])\n",
    "\n",
    "met = metrics.classification_report(test_comments['attack'], clf.predict(test_comments['comment']))\n",
    "print(met)\n",
    "\n",
    "     precision    recall  f1-score   support\n",
    "\n",
    "       False       0.95      0.95      0.95     20422\n",
    "        True       0.63      0.61      0.62      2756\n",
    "\n",
    "    accuracy                           0.91     23178\n",
    "   macro avg       0.79      0.78      0.79     23178\n",
    "weighted avg       0.91      0.91      0.91     23178\n",
    "\n",
    "**Method 1: TF-idf and Gaussian NB:** (Discarded)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 10000, ngram_range = (1,1),norm = 'l2',analyzer ='word', lowercase = True, stop_words ={'english'}, strip_accents = 'ascii')),\n",
    "    ('to_dense', DenseTransformer()), \n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "met= metrics.classification_report(y_test, y_predict)\n",
    "print(met)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predict))\n",
    "\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.95      0.53      0.68     20422\n",
    "        True       0.19      0.81      0.31      2756\n",
    "\n",
    "    accuracy                           0.56     23178\n",
    "   macro avg       0.57      0.67      0.49     23178\n",
    "weighted avg       0.86      0.56      0.64     23178\n",
    "\n",
    "**Accuracy: 0.5633359219949953**\n",
    "\n",
    "**Model 2: Using Tf-idf Vectorizer and Logistic Regression**(Discarded)\n",
    "\n",
    "model_2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 10000, ngram_range = (1,1),norm = 'l2',analyzer ='word', lowercase = True, stop_words ={'english'}, strip_accents = 'ascii')),\n",
    "    ('clf', LogisticRegression(random_state=0,max_iter = 865423))\n",
    "])\n",
    "\n",
    "model_2 = model_2.fit(X_train, y_train)\n",
    "y_predict = model_2.predict(X_test)\n",
    "met= metrics.classification_report(y_test, y_predict)\n",
    "print(met)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predict))\n",
    "\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.94      0.99      0.97     20422\n",
    "        True       0.92      0.56      0.70      2756\n",
    "\n",
    "    accuracy                           0.94     23178\n",
    "   macro avg       0.93      0.78      0.83     23178\n",
    "weighted avg       0.94      0.94      0.94     23178\n",
    "\n",
    "**Accuracy: 0.9416688238847183**\n",
    "\n",
    "**Model 3: Using Tf-idf Vectorizer and MultinomialNB**(Discarded)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 10000, ngram_range = (1,1),norm = 'l2',analyzer ='word', lowercase = True, stop_words ={'english'}, strip_accents = 'ascii')),\n",
    "    ('to_dense', DenseTransformer()), \n",
    "    ('clf', MultinomialNB(alpha =0.5))\n",
    "])\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "met= metrics.classification_report(y_test, y_predict)\n",
    "print(met)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predict))\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "       False       0.93      0.99      0.96     20422\n",
    "        True       0.92      0.49      0.64      2756\n",
    "\n",
    "    accuracy                           0.93     23178\n",
    "   macro avg       0.93      0.74      0.80     23178\n",
    "weighted avg       0.93      0.93      0.92     23178\n",
    "\n",
    "**Accuracy: 0.934075416343084**\n",
    "\n",
    "**Model 4: Using Tf-idf Vectorizer and LinearSVC**(Accepted as model)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "#('clf', LinearSVC(random_state=87,C=0.5,max_iter = 1871))\n",
    "clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 10000, ngram_range = (1,1),norm = 'l2',analyzer ='word', lowercase = True, stop_words ={'english'}, strip_accents = 'ascii')),\n",
    "    ('clf', LinearSVC(random_state=87,C=1.5,max_iter = 1871))\n",
    "])\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "met= metrics.classification_report(y_test, y_predict)\n",
    "print(met)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predict))\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       False       0.95      0.99      0.97     20422\n",
    "        True       0.86      0.65      0.74      2756\n",
    "\n",
    "    accuracy                           0.95     23178\n",
    "   macro avg       0.91      0.82      0.86     23178\n",
    "weighted avg       0.94      0.95      0.94     23178\n",
    "\n",
    "**Accuracy: 0.9464578479592717**\n",
    "\n",
    "## After balancing the imbalance data, model performances are as follows:\n",
    "\n",
    "**1. Test and train is as per column value**\n",
    "#Train and Test split\n",
    "\n",
    "train_comments = comments.query(\"split=='train'\")\n",
    "test_comments = comments.query(\"split=='test'\")\n",
    "X_train = train_comments['comment']\n",
    "y_train = train_comments['attack']\n",
    "X_test = test_comments['comment']\n",
    "y_test = test_comments['attack']\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "#('clf', LinearSVC(random_state=87,C=0.5,max_iter = 1871))\n",
    "clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features = 10000, ngram_range = (1,1),norm = 'l2',analyzer ='word', lowercase = True, stop_words ={'english'}, strip_accents = 'ascii')),\n",
    "    ('clf', LinearSVC(random_state=87,C=1.5,max_iter = 1871))\n",
    "])\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "met= metrics.classification_report(y_test, y_predict)\n",
    "print(met)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predict))\n",
    "\n",
    "\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "       False       0.80      0.96      0.88     21385\n",
    "        True       0.96      0.77      0.85     22123\n",
    "\n",
    "    accuracy                           0.87     43508\n",
    "   macro avg       0.88      0.87      0.86     43508\n",
    "weighted avg       0.88      0.87      0.86     43508\n",
    "\n",
    "**Accuracy: 0.8653351107842235**\n",
    "\n",
    "**Please note the value decreases since the data is not well shuffled between train and test after resampling**\n",
    "\n",
    "**2. Test and train is as per Holdout Estimate method(70% train, 30% test)**\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Take the comments as X\n",
    "X_df = comments.comment\n",
    "#Take the attack as class value\n",
    "y_df = comments[\"attack\"]\n",
    "#Split into test-train data, ensuring shuffling and stratification\n",
    "X_train_df, X_test_df,y_train_df, y_test_df = train_test_split(X_df,y_df,test_size=0.3,random_state = 131, shuffle = True, stratify=y_df)\n",
    "\n",
    "\n",
    "clf_4 = Pipeline([('tfidf', TfidfVectorizer(max_features = 10000, ngram_range = (1,1),norm = 'l2',analyzer ='word', lowercase = True, stop_words ={'english'}, strip_accents = 'ascii')),\n",
    "    ('clf', LinearSVC(random_state=87,C=1.5,max_iter = 1871))\n",
    "])\n",
    "clf_4 = clf_4.fit(X_train_df, y_train_df)\n",
    "y_predict_4 = clf_4.predict(X_test_df)\n",
    "met_4 = metrics.classification_report(y_test_df, y_predict_4)\n",
    "print(met_4)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_df, y_predict_4))\n",
    "\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "       False       0.99      0.95      0.97     32157\n",
    "        True       0.95      0.99      0.97     32157\n",
    "\n",
    "    accuracy                           0.97     64314\n",
    "   macro avg       0.97      0.97      0.97     64314\n",
    "weighted avg       0.97      0.97      0.97     64314\n",
    "\n",
    "**Accuracy: 0.9687315359019809**\n",
    "\n",
    "This is the Final model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Learning from different metrics\n",
    "\n",
    "In this case, since the classes are imbalanced, thus, precision-recall is a good performance measure.\n",
    "Precision is a measure of result relevancy. Recall is a measure of how many truly relevant results are returned.\n",
    "F1 score/F measure combines the precision and recall information.(Harmonic mean)\n",
    "Support is the number of actual occurrences of the class. - In this case, the support values show that there is data imbalance (possible cause of having lower value for 'True' class - *when model and evaluations are done without balancing the data).\n",
    "\n",
    "## Step 8: Improvements with Cross-Validation\n",
    "Yes, I tried cross-validation. However, it doesn't make significant improvement (since the train-test data was also shuffled already) in performance metrics (compared to final model) and consumed more time.\n",
    "\n",
    "Ex: Tried Stratified K-Fold and RepeatedStratifiedKFold (both give almost similar accuracy as Hold-out estimate method )\n",
    "\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer \n",
    "from sklearn.model_selection import RepeatedStratifiedKFold \n",
    "originalclass = [] \n",
    "predictedclass = [] \n",
    "X_df = comments.comment \n",
    "y_df = comments[\"attack\"]\n",
    "\n",
    "#Generate classification report \n",
    "def classification_report_with_accuracy_score(y_true, y_pred): \n",
    "    originalclass.extend(y_true) \n",
    "    predictedclass.extend(y_pred) \n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score\n",
    "\n",
    "outer_cv = RepeatedStratifiedKFold(n_splits=13, random_state= 1381, n_repeats = 5)\n",
    "\n",
    "clf = Pipeline([ ('tfidf', TfidfVectorizer(stop_words ={'english'}, strip_accents = 'ascii',ngram_range = (1,1))), ('clf', LinearSVC()) ])\n",
    "\n",
    "nested_score = cross_val_score(clf, X_df, y_df, cv=outer_cv, scoring=make_scorer(classification_report_with_accuracy_score)) \n",
    "print(classification_report(originalclass, predictedclass)) \n",
    "print(\"Accuracy:\", accuracy_score(originalclass, predictedclass))\n",
    "\n",
    "\n",
    "## Step 9: Final Result Metrics\n",
    "The best result is found when data is cleaned, balanced, test and train data is randomly split and **model used is : Tf-idf Vectorizer and LinearSVC**\n",
    "Compared to strawman figure the performance is improved from **91% to 97% accuracy**\n",
    "\n",
    "\n",
    "## Most intersting things learned\n",
    "User data like comments in this case can be vague. Thus, to get better analysis, a lot of factors play role.\n",
    "Data cleaning, Feature extraction, getting data split well such that class distribution is maintained (shuffling, stratification), choosing the model, hypertuning the parameters and performance evaluation.\n",
    "Each step is equally important to get the best fit.\n",
    "\n",
    "\n",
    "## Hardest thing to do\n",
    "There are lot of factors in getting a better model. Data cleaning, Features, ML model used, different ways to split data, hyperparameters, etc. Thus, there was lot of time spend on trying to understand which combination works best.\n",
    "Sometimes, making the model complex increases runtime but doesn't change the performance. This was crucial in understanding and deciding upon which model to choose."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
